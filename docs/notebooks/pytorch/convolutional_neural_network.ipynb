{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dbb6b53-f24e-43fe-b9a9-4f3614b4f96b",
   "metadata": {},
   "source": [
    "# Convolutional neural network retrieval\n",
    "\n",
    "Convolutional neural networks (CNNs) make it easy to leverage the additional structural information in the spatial retrieval input data for retrieving precipitation. This model demonstrates this using a basic UNet model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356017b8-fbc9-4755-9108-a85f3470fd0d",
   "metadata": {},
   "source": [
    "## The training data\n",
    "The SPR dataset comes in two input-data formats: *tabular* and *spatial*. The term *spatial* is used here to denote input data in 2D or image structure.\n",
    "The ``ipwgml.pytorch.dataset.SPRSpatial`` implements the PyTorch dataset interface for loading SPR data in spatial format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8015ca-c8cd-4bfd-bc2c-2677a16edbe1",
   "metadata": {},
   "source": [
    "For the CNN-based retrieval we use the gridded geometry. Apart from that we choose retrieval input and target configuration similar to those in the fully-connected NN example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30887ffe-c08d-4f9c-b8ba-9cf5edb61486",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ipwgml.input import GMI, Ancillary, Geo, GeoIR\n",
    "from ipwgml.target import TargetConfig\n",
    "\n",
    "target_config = TargetConfig(min_rqi=0.5)\n",
    "inputs = [GMI(normalize=\"minmax\", nan=-1.5)]\n",
    "geometry = \"gridded\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e12e6b9-7076-45ea-a441-e076ccb3a152",
   "metadata": {},
   "source": [
    "With these settings, we can instantiate the training data dataset. By setting ``stack=True`` we also tell the retrieval to stack all input tensors instead of loading the input data as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e679abf7-6dfc-421c-9c2d-f8eac00740e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[06/23/24 21:56:47] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> INFO:requests_cache.backends.bas<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:C</span>learing all items from the cache        <a href=\"file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py#108\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">108</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[06/23/24 21:56:47]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m INFO:requests_cache.backends.bas\u001b[1;92me:C\u001b[0mlearing all items from the cache        \u001b]8;id=796060;file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=753180;file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py#108\u001b\\\u001b[2m108\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[06/23/24 21:56:48] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> INFO:requests_cache.backends.bas<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:C</span>learing all items from the cache        <a href=\"file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py#108\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">108</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[06/23/24 21:56:48]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m INFO:requests_cache.backends.bas\u001b[1;92me:C\u001b[0mlearing all items from the cache        \u001b]8;id=416186;file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=584207;file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py#108\u001b\\\u001b[2m108\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from ipwgml.pytorch.datasets import SPRSpatial\n",
    "\n",
    "batch_size = 32\n",
    "training_data = SPRSpatial(\n",
    "    sensor=\"gmi\",\n",
    "    geometry=geometry,\n",
    "    split=\"training\",\n",
    "    retrieval_input=inputs,\n",
    "    target_config=target_config,\n",
    "    stack=True,\n",
    "    download=True,\n",
    ")\n",
    "training_loader = DataLoader(\n",
    "    training_data,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=32,\n",
    "    worker_init_fn=training_data.worker_init_fn,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdef0ac-d153-407a-9131-0ae0ab6c44ed",
   "metadata": {},
   "source": [
    "With the above configuration, the training data loaded by the ``training_loader`` has the following dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ca36f7a-f6d3-4301-b7ef-53c15bcf720f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213 ms ± 2.31 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "target_data = xr.load_dataset(training_data.target[0])\n",
    "target_time = target_data.time\n",
    "%timeit inputs[0].load_data(training_data.gmi[1], target_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5030f06c-71b2-4c89-b4ef-001439855277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.3 ms ± 192 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit inputs[0].load_data(training_data.gmi[1], target_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98456697-5599-4030-b565-bf336f7d9315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor shape:  torch.Size([32, 26, 256, 256])\n",
      "Target tensor shape:  torch.Size([32, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "inpt, target = next(iter(training_loader))\n",
    "print(\"Input tensor shape: \", inpt.shape)\n",
    "print(\"Target tensor shape: \", target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4f67a2-6adb-4266-af7a-01cc8b98c32e",
   "metadata": {},
   "source": [
    "For the validation, we instantiate dataset and dataloader with the same settings but choose the ``validation`` split instead of the ``training`` split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "242adce6-abbb-44a7-a8ea-9e7034cbd42e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[06/23/24 22:03:02] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> INFO:requests_cache.backends.bas<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:C</span>learing all items from the cache        <a href=\"file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py#108\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">108</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[06/23/24 22:03:02]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m INFO:requests_cache.backends.bas\u001b[1;92me:C\u001b[0mlearing all items from the cache        \u001b]8;id=364536;file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=924116;file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py#108\u001b\\\u001b[2m108\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> INFO:requests_cache.backends.bas<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:C</span>learing all items from the cache        <a href=\"file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py#108\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">108</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m INFO:requests_cache.backends.bas\u001b[1;92me:C\u001b[0mlearing all items from the cache        \u001b]8;id=729562;file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=708578;file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py#108\u001b\\\u001b[2m108\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "validation_data = SPRSpatial(\n",
    "    sensor=\"gmi\",\n",
    "    geometry=geometry,\n",
    "    split=\"validation\",\n",
    "    retrieval_input=inputs,\n",
    "    target_config=target_config,\n",
    "    augment=False,\n",
    "    stack=True,\n",
    "    download=True,\n",
    ")\n",
    "validation_loader = DataLoader(\n",
    "    validation_data,\n",
    "    shuffle=False,\n",
    "    batch_size=32,\n",
    "    num_workers=8,\n",
    "    worker_init_fn=validation_data.worker_init_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56751b4-c6e2-4a63-806d-3c09232fa02f",
   "metadata": {},
   "source": [
    "## UNet implementation\n",
    "\n",
    "We begin by defining the convolution block that we use to build the UNet. We choose a simple ResNet block consisting of two convolutions, each followed by normalization layer and activation function and a skip connection connecting the input to the first layer with the output of the second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1da28596-9969-48d2-93fa-1be802a454ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class ResNetBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Implments a basic ResNet block consisting of two convolutions each\n",
    "    followed by a normalization and activation layer.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: int = 3,\n",
    "        activation_fn: Callable[[], nn.Module] = nn.ReLU,\n",
    "        normalization_layer: Callable[[int], nn.Module] = nn.BatchNorm2d\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_channels: The number of channels in the input tensor.\n",
    "            out_channels: The number of channels within the layer and in the output tensor.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        padding = kernel_size // 2\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, padding=padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.projection = None\n",
    "        if in_channels != out_channels:\n",
    "            self.projection = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Propagate input through block.\n",
    "        \"\"\"\n",
    "        y = self.body(x)\n",
    "        if self.projection is None:\n",
    "            shortcut = x\n",
    "        else:\n",
    "            shortcut = self.projection(x)\n",
    "        return y + shortcut\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ea1bc40-aa0b-40e5-a0be-25eadfa051e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"\n",
    "    UNet encoder-decoder architecture for precipitation retrievals.\n",
    "\n",
    "    The model provides scalar estimates of the 'surface_precip' as well as probabilistic estimates of the\n",
    "    'probability_of_precip' and 'probability_of_heavy_precip'.\n",
    "\n",
    "    The model has the following components:\n",
    "        - Stem: The stem is applied directly to the input and maps the number of input features to\n",
    "              the features of the first encoder stage.\n",
    "        - Encoder: Applied to the output from the stem. Consists of multiple stages and performs 2x\n",
    "              downsampling at the beginning of each stage.\n",
    "        - Decoder: Each stage consists of bilinear upsampling followed by a convolution block\n",
    "              that merges the upsampled features with the output from the corresponding encoder\n",
    "              layer.\n",
    "        - Heads: A separate head for the retrieval outputs each consisting of a single ResNetBlock\n",
    "              followed by a fully-connected output layer.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_features: int,\n",
    "        internal_features: List[int],\n",
    "        **block_kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_features: The number of input features.\n",
    "            internal_features: A list containing the number of features/channels within each stage\n",
    "                of the encoder.\n",
    "            block_kwargs: Keyword arguments to forward to ResNetBlock factory.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.stem = ResNetBlock(input_features, internal_features[0])\n",
    "        chans_in = internal_features[0]\n",
    "        encoder_stages = []\n",
    "        for n_features in internal_features:\n",
    "            encoder_stages.append(nn.Sequential(\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                ResNetBlock(chans_in, n_features, **block_kwargs),\n",
    "            ))\n",
    "            chans_in = n_features\n",
    "        self.encoder = nn.ModuleList(encoder_stages)\n",
    "        \n",
    "        decoder_stages = []\n",
    "        for n_features in internal_features[-2::-1]:\n",
    "            decoder_stages.append(nn.Sequential(\n",
    "                ResNetBlock(chans_in + n_features, n_features, **block_kwargs),\n",
    "            ))\n",
    "            chans_in = n_features\n",
    "        decoder_stages.append(ResNetBlock(n_features + n_features, n_features, **block_kwargs))\n",
    "            \n",
    "        self.decoder = nn.ModuleList(decoder_stages)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode=\"bilinear\")\n",
    "        \n",
    "        heads = {}\n",
    "        for output in [\"surface_precip\", \"probability_of_precip\", \"probability_of_heavy_precip\"]:\n",
    "            heads[output] = nn.Sequential(\n",
    "                ResNetBlock(n_features, n_features, kernel_size=1, **block_kwargs),\n",
    "                nn.Conv2d(n_features, 1, kernel_size=1)\n",
    "            )\n",
    "        self.heads = nn.ModuleDict(heads)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Propagate input through network.\n",
    "\n",
    "        Args:\n",
    "            x: The tensor containing the input data.\n",
    "\n",
    "        Return:\n",
    "            A dictionary containing mapping the keys 'surface_precip', 'probability_of_precip',\n",
    "            'probability_of_heavy_precip' to the corresponding retrieval results.\n",
    "        \"\"\"\n",
    "        y = self.stem(x)\n",
    "        shortcuts = []\n",
    "        for layer in self.encoder:\n",
    "            shortcuts.append(y)\n",
    "            y = layer(y)\n",
    "\n",
    "        shortcuts.reverse()\n",
    "        for shortcut, layer in zip(shortcuts, self.decoder):\n",
    "            y = self.upsample(y)\n",
    "            y = torch.cat([y, shortcut], dim=1)\n",
    "            y = layer(y)\n",
    "\n",
    "        return {\n",
    "            name: head(y) for name, head in self.heads.items()\n",
    "        }\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fae30ed-61be-4303-8e1c-9e738325d6fd",
   "metadata": {},
   "source": [
    "Based on the UNet model defined above, we define a lightning module to manage the training of the model.\n",
    "\n",
    "The model is trained using MSE loss for the ``surface_precipitation`` output and binary cross-entropy loss for the ``probability_of_precip`` and ``probability_of_heavy_precip`` outputs. Moreover, we use the Adam optimizer with a cosine-annealing learning rate schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0279ec64-d5ab-4afe-a9d8-bed4c8a618a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Dict\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.nn.functional import binary_cross_entropy_with_logits\n",
    "import lightning as L\n",
    "\n",
    "OUTPUTS = [\n",
    "    \"surface_precip\",\n",
    "    \"probability_of_precipitation\",\n",
    "    \"probability_of_heavy_precipitation\"\n",
    "]\n",
    "\n",
    "class IPWGUNet(L.LightningModule):\n",
    "    \"\"\"\n",
    "    Lightning module implementing a multi-layer perceptron (MLP) for retrieving precipitation from satellite\n",
    "    observations.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_features: int,\n",
    "        internal_features: List[int],\n",
    "        n_epochs: int = 20,\n",
    "        **block_kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n_input_features: The number of features in the input\n",
    "            n_hidden_layers: The number of hidden layers in the MLP\n",
    "            n_neurons: The number of neurons in the hidden layers\n",
    "            activation_fn: A callable to create activation function layers.\n",
    "            normalization_layer: A callable to create normalization layers.\n",
    "            n_epochs: The numebr of epochs the model will be trained for.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.n_epochs = n_epochs\n",
    "        self.model = UNet(input_features, internal_features)\n",
    "\n",
    "    def forward(self, retrieval_input: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Forward retrieval input through network and produce dictionary with predictions.\n",
    "\n",
    "        Args:\n",
    "            retrieval_input: The retrieval input as a single torch.Tensor.\n",
    "\n",
    "        Return:\n",
    "            A dictionary containing the predictions for 'surface_precip', 'probability_of_precipitation',\n",
    "            and 'probability_of_heavy_precipitation'.\n",
    "        \"\"\"\n",
    "        return self.model(retrieval_input)\n",
    "        \n",
    "    def training_step(self, batch, batch_idx) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Calculates the loss-function gradients for the MLP.\n",
    "\n",
    "        The loss is calculated as the sum of the MSE for 'surface_precip' and the binary cross-entropy loss\n",
    "        for precipitation detection and heavy precipitation detection.\n",
    "\n",
    "        Args:\n",
    "            batch: A tuple containing the training data loaded from the data loader.\n",
    "            batch_idx: The index of the batch in the current epoch. Not used.\n",
    "\n",
    "        Return:\n",
    "            A scalar torch.Tensor containing the total loss.\n",
    "        \"\"\"\n",
    "        inpt, surface_precip = batch\n",
    "        pred = self(inpt)\n",
    "\n",
    "        valid = torch.isfinite(surface_precip)\n",
    "        surface_precip = surface_precip[valid]\n",
    "        precip_mask = (surface_precip > 1e-3).to(dtype=torch.float32)\n",
    "        heavy_precip_mask = (surface_precip > 10).to(dtype=torch.float32)\n",
    "        surface_precip_pred = pred[\"surface_precip\"][:, 0][valid]\n",
    "        pop = pred[\"probability_of_precip\"][:, 0][valid]\n",
    "        pohp = pred[\"probability_of_heavy_precip\"][:, 0][valid]\n",
    "        \n",
    "        # MSE loss for QPE\n",
    "        loss_estim = ((surface_precip_pred - surface_precip) ** 2).mean()\n",
    "        # BCE loss for detection targets\n",
    "        loss_detect = binary_cross_entropy_with_logits(pop, precip_mask)\n",
    "        loss_detect_heavy = binary_cross_entropy_with_logits(pohp, heavy_precip_mask)\n",
    "        tot_loss =  loss_estim + loss_detect + loss_detect_heavy\n",
    "        return tot_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx) -> None:\n",
    "        \"\"\"\n",
    "        Calculates the loss-function values on validation data.\n",
    "\n",
    "        Args:\n",
    "            batch: A tuple containing the training data loaded from the data loader.\n",
    "            batch_idx: The index of the batch in the current epoch. Not used.\n",
    "        \"\"\"\n",
    "        inpt, surface_precip = batch\n",
    "        pred = self(inpt)\n",
    "\n",
    "        valid = torch.isfinite(surface_precip)\n",
    "        surface_precip = surface_precip[valid]\n",
    "        precip_mask = (surface_precip > 1e-3).to(dtype=torch.float32)\n",
    "        heavy_precip_mask = (surface_precip > 10).to(dtype=torch.float32)\n",
    "        surface_precip_pred = pred[\"surface_precip\"][:, 0][valid]\n",
    "        pop = pred[\"probability_of_precip\"][:, 0][valid]\n",
    "        pohp = pred[\"probability_of_heavy_precip\"][:, 0][valid]\n",
    "        \n",
    "        # MSE loss for QPE\n",
    "        loss_estim = ((surface_precip_pred - surface_precip) ** 2).mean()\n",
    "        # BCE loss for detection targets\n",
    "        loss_detect = binary_cross_entropy_with_logits(pop, precip_mask)\n",
    "        loss_detect_heavy = binary_cross_entropy_with_logits(pohp, heavy_precip_mask)\n",
    "        tot_loss =  loss_estim + loss_detect + loss_detect_heavy\n",
    "\n",
    "        opt = self.optimizers()\n",
    "        learning_rate = opt.param_groups[0]['lr']\n",
    "        \n",
    "        self.log_dict(\n",
    "            {\n",
    "                \"val_loss\": loss_estim + loss_detect + loss_detect_heavy,\n",
    "                \"val_loss_estim\": loss_estim,\n",
    "                \"val_loss_detect\": loss_detect,\n",
    "                \"val_loss_detect_heavy\": loss_detect_heavy,\n",
    "                \"learning_rate\": learning_rate\n",
    "            },\n",
    "            on_epoch=True,\n",
    "            prog_bar=True\n",
    "        )\n",
    "    \n",
    "    def configure_optimizers(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        We use the Adam optimizer with a cosine annealing learning rate schedule.\n",
    "        \"\"\"\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=self.n_epochs)\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": scheduler\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf6d261-6a8a-468d-abfc-e1e2e8da5339",
   "metadata": {},
   "source": [
    "### Running the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e42aaba-5d99-40b9-81e1-1aa0e020f6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipwgml.input import calculate_input_features\n",
    "\n",
    "input_features = calculate_input_features(inputs)\n",
    "ipwg_unet = IPWGUNet(input_features=input_features, internal_features=[32, 64, 128, 256, 512], n_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1abe1ccb-6fac-4e41-8613-684fd7317677",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[06/23/24 22:03:11] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> INFO:lightning.pytorch.utilities.rank_zero:GPU available: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span> <span style=\"font-weight: bold\">(</span>cuda<span style=\"font-weight: bold\">)</span>, <a href=\"file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">rank_zero.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py#63\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">63</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         used: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[06/23/24 22:03:11]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m INFO:lightning.pytorch.utilities.rank_zero:GPU available: \u001b[3;92mTrue\u001b[0m \u001b[1m(\u001b[0mcuda\u001b[1m)\u001b[0m, \u001b]8;id=313290;file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py\u001b\\\u001b[2mrank_zero.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=959767;file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py#63\u001b\\\u001b[2m63\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         used: \u001b[3;92mTrue\u001b[0m                                                             \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> INFO:lightning.pytorch.utilities.rank_zero:TPU available: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,       <a href=\"file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">rank_zero.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py#63\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">63</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         using: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> TPU cores                                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m INFO:lightning.pytorch.utilities.rank_zero:TPU available: \u001b[3;91mFalse\u001b[0m,       \u001b]8;id=272093;file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py\u001b\\\u001b[2mrank_zero.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=9360;file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py#63\u001b\\\u001b[2m63\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         using: \u001b[1;36m0\u001b[0m TPU cores                                                     \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> INFO:lightning.pytorch.utilities.rank_zero:IPU available: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,       <a href=\"file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">rank_zero.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py#63\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">63</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         using: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> IPUs                                                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m INFO:lightning.pytorch.utilities.rank_zero:IPU available: \u001b[3;91mFalse\u001b[0m,       \u001b]8;id=560129;file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py\u001b\\\u001b[2mrank_zero.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=585713;file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py#63\u001b\\\u001b[2m63\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         using: \u001b[1;36m0\u001b[0m IPUs                                                          \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> INFO:lightning.pytorch.utilities.rank_zero:HPU available: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,       <a href=\"file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">rank_zero.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py#63\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">63</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         using: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> HPUs                                                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m INFO:lightning.pytorch.utilities.rank_zero:HPU available: \u001b[3;91mFalse\u001b[0m,       \u001b]8;id=395981;file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py\u001b\\\u001b[2mrank_zero.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=280962;file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py#63\u001b\\\u001b[2m63\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         using: \u001b[1;36m0\u001b[0m HPUs                                                          \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: You are using a CUDA device ('NVIDIA RTX 6000 Ada Generation') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> INFO:lightning.pytorch.utilities.rank_zero:You are using a CUDA device <a href=\"file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">rank_zero.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py#63\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">63</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'NVIDIA RTX 6000 Ada Generation'</span><span style=\"font-weight: bold\">)</span> that has Tensor Cores. To properly  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         utilize them, you should set                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         `<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.set_float32_matmul_precision</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'medium'</span> | <span style=\"color: #008000; text-decoration-color: #008000\">'high'</span><span style=\"font-weight: bold\">)</span>` which will     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         trade-off precision for performance. For more details, read            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_pre</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">cision.html#torch.set_float32_matmul_precision</span>                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m INFO:lightning.pytorch.utilities.rank_zero:You are using a CUDA device \u001b]8;id=901715;file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py\u001b\\\u001b[2mrank_zero.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=29665;file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py#63\u001b\\\u001b[2m63\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1m(\u001b[0m\u001b[32m'NVIDIA RTX 6000 Ada Generation'\u001b[0m\u001b[1m)\u001b[0m that has Tensor Cores. To properly  \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         utilize them, you should set                                           \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         `\u001b[1;35mtorch.set_float32_matmul_precision\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'medium'\u001b[0m | \u001b[32m'high'\u001b[0m\u001b[1m)\u001b[0m` which will     \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         trade-off precision for performance. For more details, read            \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;94mhttps://pytorch.org/docs/stable/generated/torch.set_float32_matmul_pre\u001b[0m \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;94mcision.html#torch.set_float32_matmul_precision\u001b[0m                         \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> -                    <a href=\"file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning/pytorch/accelerators/cuda.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">cuda.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning/pytorch/accelerators/cuda.py#61\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">61</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         CUDA_VISIBLE_DEVICES: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>                                                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">          </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: \u001b[1;36m0\u001b[0m -                    \u001b]8;id=183621;file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning/pytorch/accelerators/cuda.py\u001b\\\u001b[2mcuda.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=855520;file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning/pytorch/accelerators/cuda.py#61\u001b\\\u001b[2m61\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         CUDA_VISIBLE_DEVICES: \u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m                                                   \u001b[2m          \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: \n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | UNet | 8.4 M \n",
      "-------------------------------\n",
      "8.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "8.4 M     Total params\n",
      "33.408    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> INFO:lightning.pytorch.callbacks.model_summary:                    <a href=\"file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_summary.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_summary.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_summary.py#94\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">94</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           | Name  | Type | Params                                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         -------------------------------                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> | model | UNet | <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.4</span> M                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         -------------------------------                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.4</span> M     Trainable params                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>         Non-trainable params                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.4</span> M     Total params                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33.408</span>    Total estimated model params size <span style=\"font-weight: bold\">(</span>MB<span style=\"font-weight: bold\">)</span>                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m INFO:lightning.pytorch.callbacks.model_summary:                    \u001b]8;id=707737;file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_summary.py\u001b\\\u001b[2mmodel_summary.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=171847;file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_summary.py#94\u001b\\\u001b[2m94\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m           | Name  | Type | Params                                          \u001b[2m                   \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         -------------------------------                                    \u001b[2m                   \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;36m0\u001b[0m | model | UNet | \u001b[1;36m8.4\u001b[0m M                                           \u001b[2m                   \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         -------------------------------                                    \u001b[2m                   \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;36m8.4\u001b[0m M     Trainable params                                         \u001b[2m                   \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;36m0\u001b[0m         Non-trainable params                                     \u001b[2m                   \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;36m8.4\u001b[0m M     Total params                                             \u001b[2m                   \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1;36m33.408\u001b[0m    Total estimated model params size \u001b[1m(\u001b[0mMB\u001b[1m)\u001b[0m                   \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                      | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e16fa0f6f2f42908ff590d92068357d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "Caught KeyError in DataLoader worker process 21.\nOriginal Traceback (most recent call last):\n  File \"/home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/xarray/core/dataset.py\", line 1436, in _copy_listed\n    variables[name] = self._variables[name]\nKeyError: 'observations'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/simon/src/ipwgml/src/ipwgml/pytorch/datasets.py\", line 416, in __getitem__\n    data = inpt.load_data(files[ind], target_time=target_time)\n  File \"/home/simon/src/ipwgml/src/ipwgml/input.py\", line 247, in load_data\n    pmw_data = pmw_data[[\"observations\", \"earth_incidence_angle\"]].transpose(\"channel\", ...)\n  File \"/home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/xarray/core/dataset.py\", line 1580, in __getitem__\n    return self._copy_listed(key)\n  File \"/home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/xarray/core/dataset.py\", line 1438, in _copy_listed\n    ref_name, var_name, var = _get_virtual_variable(\n  File \"/home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/xarray/core/dataset.py\", line 209, in _get_virtual_variable\n    raise KeyError(key)\nKeyError: 'observations'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m L\u001b[38;5;241m.\u001b[39mTrainer(max_epochs\u001b[38;5;241m=\u001b[39mipwg_unet\u001b[38;5;241m.\u001b[39mn_epochs)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mipwg_unet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    574\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    576\u001b[0m     ckpt_path,\n\u001b[1;32m    577\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m )\n\u001b[0;32m--> 580\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:987\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 987\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    992\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1033\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[1;32m   1032\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1033\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:205\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:363\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py:140\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py:212\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m     batch, _, __ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# TODO: we should instead use the batch_idx returned by the fetcher, however, that will require saving the\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# fetcher state so that the batch_idx is correct after restarting\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     batch_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning/pytorch/loops/fetchers.py:133\u001b[0m, in \u001b[0;36m_PrefetchDataFetcher.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatches\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# this will run only when no pre-fetching was done.\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__next__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# the iterator is empty\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning/pytorch/loops/fetchers.py:60\u001b[0m, in \u001b[0;36m_DataFetcher.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_profiler()\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning/pytorch/utilities/combined_loader.py:341\u001b[0m, in \u001b[0;36mCombinedLoader.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _ITERATOR_RETURN:\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 341\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator, _Sequential):\n\u001b[1;32m    343\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/envs/ipwgml/lib/python3.10/site-packages/lightning/pytorch/utilities/combined_loader.py:78\u001b[0m, in \u001b[0;36m_MaxSizeCycle.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m         out[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterators\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consumed[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ipwgml/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/ipwgml/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1326\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rcvd_idx]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   1325\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rcvd_idx)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_data()\n",
      "File \u001b[0;32m~/miniconda3/envs/ipwgml/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1372\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1372\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/ipwgml/lib/python3.10/site-packages/torch/_utils.py:705\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 705\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mKeyError\u001b[0m: Caught KeyError in DataLoader worker process 21.\nOriginal Traceback (most recent call last):\n  File \"/home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/xarray/core/dataset.py\", line 1436, in _copy_listed\n    variables[name] = self._variables[name]\nKeyError: 'observations'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/simon/src/ipwgml/src/ipwgml/pytorch/datasets.py\", line 416, in __getitem__\n    data = inpt.load_data(files[ind], target_time=target_time)\n  File \"/home/simon/src/ipwgml/src/ipwgml/input.py\", line 247, in load_data\n    pmw_data = pmw_data[[\"observations\", \"earth_incidence_angle\"]].transpose(\"channel\", ...)\n  File \"/home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/xarray/core/dataset.py\", line 1580, in __getitem__\n    return self._copy_listed(key)\n  File \"/home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/xarray/core/dataset.py\", line 1438, in _copy_listed\n    ref_name, var_name, var = _get_virtual_variable(\n  File \"/home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/xarray/core/dataset.py\", line 209, in _get_virtual_variable\n    raise KeyError(key)\nKeyError: 'observations'\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(max_epochs=ipwg_unet.n_epochs)\n",
    "trainer.fit(model=ipwg_unet, train_dataloaders=training_loader, val_dataloaders=validation_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31360065-cb8a-421e-bd58-4d61f4a01683",
   "metadata": {},
   "source": [
    "# Evaluating the retrieval\n",
    "\n",
    "To evaluate the retrieval using the ``ipwgml.evaluation.Evaluator`` class, we need to define a retrieval callback function that performes inferences on the retrieval input data provided by the evaluator. The ``ipwgml.pytorch`` module provides the ``PytorchRetrieval`` helper class that wraps around a trained PyTorch neural network and acts as a ``retrieval_fn`` that can be passed to the evaluator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25aa411a-d918-4afc-8ea8-83288a5de428",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipwgml.pytorch import PytorchRetrieval\n",
    "unet_retrieval = PytorchRetrieval(\n",
    "    ipwg_unet,\n",
    "    retrieval_input=inputs,\n",
    "    stack=True,\n",
    "    device=torch.device(\"cuda\"),\n",
    "    dtype=torch.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c33ff035-fff2-4d35-ba80-bb1c04997aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[06/23/24 21:10:47] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> INFO:requests_cache.backends.bas<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:C</span>learing all items from the cache        <a href=\"file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py#108\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">108</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[06/23/24 21:10:47]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m INFO:requests_cache.backends.bas\u001b[1;92me:C\u001b[0mlearing all items from the cache        \u001b]8;id=527005;file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=578865;file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py#108\u001b\\\u001b[2m108\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> INFO:requests_cache.backends.bas<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:C</span>learing all items from the cache        <a href=\"file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py#108\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">108</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m INFO:requests_cache.backends.bas\u001b[1;92me:C\u001b[0mlearing all items from the cache        \u001b]8;id=873655;file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=397110;file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py#108\u001b\\\u001b[2m108\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> INFO:requests_cache.backends.bas<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:C</span>learing all items from the cache        <a href=\"file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py#108\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">108</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m INFO:requests_cache.backends.bas\u001b[1;92me:C\u001b[0mlearing all items from the cache        \u001b]8;id=5153;file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=531446;file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py#108\u001b\\\u001b[2m108\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> INFO:requests_cache.backends.bas<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:C</span>learing all items from the cache        <a href=\"file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py#108\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">108</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m INFO:requests_cache.backends.bas\u001b[1;92me:C\u001b[0mlearing all items from the cache        \u001b]8;id=572319;file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=162562;file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py#108\u001b\\\u001b[2m108\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> INFO:requests_cache.backends.bas<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:C</span>learing all items from the cache        <a href=\"file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py#108\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">108</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m INFO:requests_cache.backends.bas\u001b[1;92me:C\u001b[0mlearing all items from the cache        \u001b]8;id=658441;file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=959030;file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py#108\u001b\\\u001b[2m108\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> INFO:requests_cache.backends.bas<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:C</span>learing all items from the cache        <a href=\"file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py#108\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">108</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m INFO:requests_cache.backends.bas\u001b[1;92me:C\u001b[0mlearing all items from the cache        \u001b]8;id=882708;file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=521458;file:///home/simon/miniconda3/envs/ipwgml/lib/python3.10/site-packages/requests_cache/backends/base.py#108\u001b\\\u001b[2m108\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipwgml.evaluation import Evaluator\n",
    "evaluator = Evaluator(\n",
    "    sensor=\"gmi\",\n",
    "    geometry=geometry,\n",
    "    retrieval_input=inputs,\n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f1aae8-02fc-4b3a-ac1d-c8399a20fe0b",
   "metadata": {},
   "source": [
    "## Case study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7b3281-e29d-41b3-ab06-4a0640a7d3da",
   "metadata": {},
   "source": [
    "## Running the evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "feecab9b-0041-4d77-9f5b-fe6c9a55969f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "957de74c3ff74c5393887aaa4535114f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluator.evaluate(\n",
    "    retrieval_fn=unet_retrieval,\n",
    "    input_data_format=\"spatial\",\n",
    "    batch_size=32,\n",
    "    n_processes=1,\n",
    "    tile_size=256,\n",
    "    overlap=64,\n",
    "    output_path=\".\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73db7940-3e8e-4123-9c5d-05389b1ef093",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b3facb-35b6-4bc4-b1a7-3a4bdbd1bc00",
   "metadata": {},
   "source": [
    "### Precipitation estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f39561e7-fa2a-432c-afdf-6c69ed893b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simon/src/ipwgml/src/ipwgml/metrics.py:645: RuntimeWarning: invalid value encountered in divide\n",
      "  sigma_target = w_target_s2 / counts - (w_target_s / counts) ** 2\n",
      "/home/simon/src/ipwgml/src/ipwgml/metrics.py:646: RuntimeWarning: invalid value encountered in divide\n",
      "  sigma_pred = w_pred_s2 / counts - (w_pred_s / counts) ** 2\n",
      "/home/simon/src/ipwgml/src/ipwgml/metrics.py:647: RuntimeWarning: invalid value encountered in divide\n",
      "  target_mean = w_target_s / counts\n",
      "/home/simon/src/ipwgml/src/ipwgml/metrics.py:648: RuntimeWarning: invalid value encountered in divide\n",
      "  pred_mean = w_pred_s / counts\n",
      "/home/simon/src/ipwgml/src/ipwgml/metrics.py:649: RuntimeWarning: invalid value encountered in divide\n",
      "  targetpred_mean = w_targetpred_s / counts\n",
      "/home/simon/src/ipwgml/src/ipwgml/metrics.py:654: RuntimeWarning: invalid value encountered in divide\n",
      "  co = np.abs(w_targetpred_s) / (np.sqrt(w_target_s2) * np.sqrt(w_pred_s2))\n",
      "/home/simon/src/ipwgml/src/ipwgml/metrics.py:672: RuntimeWarning: invalid value encountered in divide\n",
      "  se, _ = np.histogram(n, weights=w_d_s2 / self.counts, bins=bins)\n",
      "/home/simon/src/ipwgml/src/ipwgml/metrics.py:677: RuntimeWarning: divide by zero encountered in divide\n",
      "  scales = 0.5 * (N - 1) * self.scale / n\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNet (CPCIR)</th>\n",
       "      <th>IMERG Final V7 (GMI)</th>\n",
       "      <th>GPROF V7 (GMI)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bias [$\\%$]</th>\n",
       "      <td>-15.526079</td>\n",
       "      <td>-7.398772</td>\n",
       "      <td>5.799770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE [$mm h^{-1}$]</th>\n",
       "      <td>0.161556</td>\n",
       "      <td>0.124924</td>\n",
       "      <td>0.119785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE [$(mm h^{-1})^2$]</th>\n",
       "      <td>1.845625</td>\n",
       "      <td>1.731411</td>\n",
       "      <td>1.413339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMAPE$_{0.1}$ [$\\%$]</th>\n",
       "      <td>102.541505</td>\n",
       "      <td>114.417614</td>\n",
       "      <td>91.327371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Correlation coeff. []</th>\n",
       "      <td>0.493592</td>\n",
       "      <td>0.455411</td>\n",
       "      <td>0.552348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Effective resolution [$^\\circ$]</th>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.423000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 UNet (CPCIR)  IMERG Final V7 (GMI)  \\\n",
       "Bias [$\\%$]                        -15.526079             -7.398772   \n",
       "MAE [$mm h^{-1}$]                    0.161556              0.124924   \n",
       "MSE [$(mm h^{-1})^2$]                1.845625              1.731411   \n",
       "SMAPE$_{0.1}$ [$\\%$]               102.541505            114.417614   \n",
       "Correlation coeff. []                0.493592              0.455411   \n",
       "Effective resolution [$^\\circ$]           inf                   inf   \n",
       "\n",
       "                                 GPROF V7 (GMI)  \n",
       "Bias [$\\%$]                            5.799770  \n",
       "MAE [$mm h^{-1}$]                      0.119785  \n",
       "MSE [$(mm h^{-1})^2$]                  1.413339  \n",
       "SMAPE$_{0.1}$ [$\\%$]                  91.327371  \n",
       "Correlation coeff. []                  0.552348  \n",
       "Effective resolution [$^\\circ$]        0.423000  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.get_precip_quantification_results(name=\"UNet (CPCIR)\").T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d719d4a-37e8-4c87-8848-fa41720cf220",
   "metadata": {},
   "source": [
    "### Precipitation detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fe10ae8f-3e2e-494d-acc6-dd24b2e5698a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNet (CPCIR)</th>\n",
       "      <th>IMERG Final V7 (GMI)</th>\n",
       "      <th>GPROF V7 (GMI)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>POD []</th>\n",
       "      <td>0.382926</td>\n",
       "      <td>0.687576</td>\n",
       "      <td>0.758366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAR []</th>\n",
       "      <td>0.356477</td>\n",
       "      <td>0.497714</td>\n",
       "      <td>0.462010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HSS []</th>\n",
       "      <td>0.633071</td>\n",
       "      <td>0.470956</td>\n",
       "      <td>0.508161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        UNet (CPCIR)  IMERG Final V7 (GMI)  GPROF V7 (GMI)\n",
       "POD []      0.382926              0.687576        0.758366\n",
       "FAR []      0.356477              0.497714        0.462010\n",
       "HSS []      0.633071              0.470956        0.508161"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.get_precip_detection_results(name=\"UNet (CPCIR)\").T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6073b1-e718-4a34-825a-78d85e5783fb",
   "metadata": {},
   "source": [
    "### Probabilistic precipitation detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cfb004f2-f157-49b9-90fe-2b88112670dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simon/src/ipwgml/src/ipwgml/metrics.py:904: RuntimeWarning: invalid value encountered in divide\n",
      "  precision = self.n_tp / (self.n_tp + self.n_fp)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNet (CPCIR)</th>\n",
       "      <th>IMERG Final V7 (GMI)</th>\n",
       "      <th>GPROF V7 (GMI)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUC []</th>\n",
       "      <td>0.557225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.54994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        UNet (CPCIR)  IMERG Final V7 (GMI)  GPROF V7 (GMI)\n",
       "AUC []      0.557225                   0.0         0.54994"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.get_prob_precip_detection_results(name=\"UNet (CPCIR)\").T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d8f381-620b-4318-8425-247830d32c1f",
   "metadata": {},
   "source": [
    "### Heavy precipitation detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cbac425c-54b6-4bac-99cb-8d84524e9c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNet (CPCIR)</th>\n",
       "      <th>IMERG Final V7 (GMI)</th>\n",
       "      <th>GPROF V7 (GMI)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>POD []</th>\n",
       "      <td>0.062328</td>\n",
       "      <td>0.687576</td>\n",
       "      <td>0.758366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAR []</th>\n",
       "      <td>0.424756</td>\n",
       "      <td>0.497714</td>\n",
       "      <td>0.462010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HSS []</th>\n",
       "      <td>0.575115</td>\n",
       "      <td>0.470956</td>\n",
       "      <td>0.508161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        UNet (CPCIR)  IMERG Final V7 (GMI)  GPROF V7 (GMI)\n",
       "POD []      0.062328              0.687576        0.758366\n",
       "FAR []      0.424756              0.497714        0.462010\n",
       "HSS []      0.575115              0.470956        0.508161"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.get_heavy_precip_detection_results(name=\"UNet (CPCIR)\").T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701b282b-13df-4c6f-8a3c-cb6e3dd053fb",
   "metadata": {},
   "source": [
    "### Probabilistic heavy precipitation detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "57681c38-b4b0-498c-bc25-af21a1c01548",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simon/src/ipwgml/src/ipwgml/metrics.py:904: RuntimeWarning: invalid value encountered in divide\n",
      "  precision = self.n_tp / (self.n_tp + self.n_fp)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNet (CPCIR)</th>\n",
       "      <th>IMERG Final V7 (GMI)</th>\n",
       "      <th>GPROF V7 (GMI)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUC []</th>\n",
       "      <td>0.245186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.298044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        UNet (CPCIR)  IMERG Final V7 (GMI)  GPROF V7 (GMI)\n",
       "AUC []      0.245186                   0.0        0.298044"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.get_prob_heavy_precip_detection_results(name=\"UNet (CPCIR)\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b605f7e-7a5f-42b8-9b5c-b8883ff6300d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
